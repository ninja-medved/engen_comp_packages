{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "0tJg8ISAr1xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import word_tokenize \n",
        "import pymorphy2\n",
        "import difflib as df\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "gK9PQq-gy4Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функция для лемматизации текста, на вход принимает список токенов \n",
        "def lemmatize_text(tokens):\n",
        "    # создаем переменную для хранения преобразованного текста\n",
        "    text_new=''\n",
        "    # для каждого токена в тексте\n",
        "    for word in tokens:\n",
        "        # с помощью лемматайзера получаем основную форму\n",
        "        word = lemmatizer.parse(word)\n",
        "        # добавляем полученную лемму в переменную с преобразованным текстом\n",
        "        text_new = text_new + ' ' + word[0].normal_form\n",
        "    # возвращаем преобразованный текст\n",
        "    return text_new\n",
        "\n",
        "# инициализируем лемматайзер MorphAnalyzer()\n",
        "lemmatizer = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "QrDMHVRcy_-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kypz7xMMaNX3"
      },
      "outputs": [],
      "source": [
        "#считывание данных из файла\n",
        "data = pd.read_csv('staff_diplom.csv', on_bad_lines='skip', delimiter = ';')\n",
        "data.head(20)\n",
        "\n",
        "#создаем облако всех слов\n",
        "text = str()\n",
        "for i in range(int(data.size/5)):\n",
        "  text += ' '.join([str(data.iloc[i]['title']) if str(data.iloc[i]['title']) != '\\'' else ''])\n",
        "stop_words = stopwords.words('russian')\n",
        "\n",
        "text = word_tokenize(text)\n",
        " \n",
        "#вызываем функцию лемматизации для списка токенов исходного текста\n",
        "text = lemmatize_text(text)\n",
        "wlist = text.split(sep = ' ')\n",
        "fdist = FreqDist(wlist)\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выводим облако слов на экран\n",
        "cloud = WordCloud(max_font_size=25, max_words=400, background_color=\"white\", stopwords=stop_words).generate(text)\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "\n",
        "plt.imshow(cloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "OhGomOvkUEqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "themes = {\"моделирование\":0, \"метод машинного обучения\":0, \"нейронные сети\":0, \"управление\":0, \"динамические системы\":0, \"реализация и разработка алгоритма\":0, \"оптимизация моделей и систем\":0, \"прогнозирование\":0, \"дифференцирование\":0, \"решение задач\":0, \"информационные технологии\":0, \"разработка систем\":0, \"другое\":0}\n",
        "print(themes)\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "19AFcDsHzhiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "types_of_departments = set()\n",
        "for dep in data['department']:\n",
        "  types_of_departments.add(dep)\n",
        "  \n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "kEBmKzJlvm_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "themes = {\"моделирование\":0, \"метод машинного обучения\":0, \"нейронные сети\":0, \"управление\":0, \"динамические системы\":0, \"реализация и разработка алгоритма\":0, \"оптимизация моделей и систем\":0, \"прогнозирование\":0, \"дифференцирование\":0, \"решение задач\":0, \"информационные технологии\":0, \"разработка систем\":0, \"другое\":0}\n",
        "\n",
        "years = dict()\n",
        "for i in range(1994, 2022):\n",
        "  years[str(i)] = {\"моделирование\":0, \"метод машинного обучения\":0, \"нейронные сети\":0, \"управление\":0, \"динамические системы\":0, \"реализация и разработка алгоритма\":0, \"оптимизация моделей и систем\":0, \"прогнозирование\":0, \"дифференцирование\":0, \"решение задач\":0, \"информационные технологии\":0, \"разработка систем\":0, \"другое\":0}\n",
        "years[\"NaN\"] = {\"моделирование\":0, \"метод машинного обучения\":0, \"нейронные сети\":0, \"управление\":0, \"динамические системы\":0, \"реализация и разработка алгоритма\":0, \"оптимизация моделей и систем\":0, \"прогнозирование\":0, \"дифференцирование\":0, \"решение задач\":0, \"информационные технологии\":0, \"разработка систем\":0, \"другое\":0}\n",
        "\n",
        "masters = {\"моделирование\":\"\", \"метод машинного обучения\":\"\", \"нейронные сети\":\"\", \"управление\":\"\", \"динамические системы\":\"\", \"реализация и разработка алгоритма\":\"\", \"оптимизация моделей и систем\":\"\", \"прогнозирование\":\"\", \"дифференцирование\":\"\", \"решение задач\":\"\", \"информационные технологии\":\"\", \"разработка систем\":\"\", \"другое\":\"\"}\n",
        "\n",
        "departments = dict()\n",
        "for i in types_of_departments:\n",
        "  departments[str(i)] = {\"моделирование\":0, \"метод машинного обучения\":0, \"нейронные сети\":0, \"управление\":0, \"динамические системы\":0, \"реализация и разработка алгоритма\":0, \"оптимизация моделей и систем\":0, \"прогнозирование\":0, \"дифференцирование\":0, \"решение задач\":0, \"информационные технологии\":0, \"разработка систем\":0, \"другое\":0}\n",
        "\n",
        "\n",
        "d = df.Differ()\n",
        "\n",
        "def similarity(s1, s2):\n",
        "  try:\n",
        "    normalized1 = s1.lower()\n",
        "    normalized2 = s2.lower()\n",
        "    matcher = df.SequenceMatcher(None, normalized1, normalized2)\n",
        "    return matcher.ratio()\n",
        "  except:\n",
        "    return 0\n",
        "\n",
        "for i in range(int(data.size/5)):\n",
        "  means = list()\n",
        "  max = 0\n",
        "  tmp = \"\"\n",
        "  first = data.iloc[i]['title']\n",
        "\n",
        "  try:\n",
        "    year = str(int(data.iloc[i]['year']))\n",
        "  except:\n",
        "    year = \"NaN\"\n",
        "\n",
        "  master = data.iloc[i]['staffid']\n",
        "\n",
        "  department = str(data.iloc[i]['department'])\n",
        "  \n",
        "  try:\n",
        "    first = word_tokenize(first)\n",
        "    first = lemmatize_text(first)\n",
        "    for key in themes.keys():\n",
        "      second = key\n",
        "      second = word_tokenize(second)\n",
        "      second = lemmatize_text(second)\n",
        "      diff = similarity(first, second)    \n",
        "      means.append(diff)\n",
        "      if diff > max: \n",
        "        max = diff\n",
        "        tmp_themes = key\n",
        "        tmp_years = year\n",
        "\n",
        "    if max > 0.25:\n",
        "      themes[tmp_themes] += 1\n",
        "      years[year][tmp_themes] += 1 \n",
        "      masters[tmp_themes] += master + ' '   \n",
        "      departments[department][tmp_themes] += 1\n",
        "    else:\n",
        "      themes[\"другое\"] += 1\n",
        "      years[year][\"другое\"] += 1\n",
        "      masters[\"другое\"] += master + ' '  \n",
        "      departments[department][\"другое\"] += 1\n",
        "  except:\n",
        "    print(end = '')\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "uC08Ibcs_1vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#вывод тем по тематикам\n",
        "\n",
        "print(themes)\n",
        "fig = plt.figure(figsize=(30, 15))  \n",
        "plt.bar(themes.keys(), themes.values(), width=1, color='g')      \n",
        "plt.title(\"Тематики\")          \n",
        "plt.show()\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "KWz89-fIMMJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#вывод преподавателей по тематикам\n",
        "\n",
        "for theme, master in masters.items():\n",
        "  fmasters = FreqDist(master.split(sep = ' '))\n",
        "  secondName, valuse = fmasters.most_common(1)[0]\n",
        "  print(theme, ': ', secondName, ' - ', valuse)\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "s-oQPdSoMgdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#вывод тематик по годам\n",
        "\n",
        "rows = int(len(years)/4) + 1\n",
        "columns = 4\n",
        "k=0\n",
        "fig, ax = plt.subplots(rows, columns, figsize=(20,40))\n",
        "for year, theme in years.items():  \n",
        "  ax[int(k / 4)][int(k % 4)].bar(range(13), theme.values(), width=1, color='g')  \n",
        "  ax[int(k / 4)][int(k % 4)].set_title(year)\n",
        "  k+=1               \n",
        "plt.show()\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "zIqFkFFzNOVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataf = pd.DataFrame(columns=[\"department\", \"themes\", \"means\"])\n",
        "\n",
        "for tmpdepartment, tmpdata in departments.items():\n",
        "  for tmpthemes, tmpmeans in tmpdata.items():\n",
        "    new_row = {\"department\": tmpdepartment, \"themes\": tmpthemes, \"means\": float(tmpmeans)}\n",
        "    dataf = dataf.append(new_row, ignore_index=True)\n",
        "\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "plt.scatter(x=dataf[\"department\"], \n",
        "            y=dataf[\"themes\"],\n",
        "            s=dataf[\"means\"]*10)\n",
        "plt.show()\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "Jq2jwf3MsKJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#создаем облако слов для каждого преподавателя\n",
        "teachers = dict()\n",
        "\n",
        "for i in range(int(data.size/5)):\n",
        "  if data.iloc[i]['staffid'] not in teachers:\n",
        "    teachers[data.iloc[i]['staffid']] = data.iloc[i]['title']\n",
        "  else:\n",
        "    teachers[data.iloc[i]['staffid']] += ''.join([str(data.iloc[i]['title']) if str(data.iloc[i]['title']) != '\\'' else ''])\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(20,14))\n",
        "rows = 2\n",
        "columns = 5\n",
        "\n",
        "k = 0\n",
        "for pair in teachers.items():\n",
        "  if k == 3: \n",
        "    break\n",
        "  k+=1\n",
        "  teacher, words = pair\n",
        "  words = word_tokenize(words)\n",
        "  words = lemmatize_text(words)\n",
        "  fig.add_subplot(rows, columns, k)\n",
        "  cloud = WordCloud(stopwords=stop_words).generate(words)\n",
        "  # Выводим облако слов на экран\n",
        "  plt.imshow(cloud)\n",
        "  # Отключаем отображение осей\n",
        "  plt.axis('off')\n",
        "  plt.title(teacher)\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "5sWOweIIynS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#создаем облако слов для каждой кафедры\n",
        "departmanets = dict()\n",
        "\n",
        "for i in range(int(data.size/5)):\n",
        "  if data.iloc[i]['department'] not in departmanets:\n",
        "    departmanets[data.iloc[i]['department']] = data.iloc[i]['title']\n",
        "  else:\n",
        "    departmanets[data.iloc[i]['department']] += ''.join([str(data.iloc[i]['title']) if str(data.iloc[i]['title']) != '\\'' else ''])\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(20,14))\n",
        "rows = 2\n",
        "columns = 5\n",
        "\n",
        "k = 0\n",
        "for pair in departmanets.items():\n",
        "  if k == 3: \n",
        "    break\n",
        "  k+=1\n",
        "  department, words = pair\n",
        "  words = word_tokenize(words)\n",
        "  words = lemmatize_text(words)\n",
        "  fig.add_subplot(rows, columns, k)\n",
        "  cloud = WordCloud(stopwords=stop_words).generate(words)\n",
        "  # Выводим облако слов на экран\n",
        "  plt.imshow(cloud)\n",
        "  # Отключаем отображение осей\n",
        "  plt.axis('off')\n",
        "  plt.title(department)\n",
        "\n",
        "print('---------------------------Done---------------------------')"
      ],
      "metadata": {
        "id": "j5Mo8kW0yBDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xqmNWeSop8GA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}